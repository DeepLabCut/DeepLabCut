data:
  inference:
    top_down_crop:
      width: 384
      height: 384
  train:
    top_down_crop:
      width: 384
      height: 384
  bbox_margin: 25
  gen_sampling_sigmas: 0.1
  gen_sampling_symmetries: []
method: ctd
model:
  backbone:
    type: CondPreNet
    backbone:
      type: CSPNeXt
      model_name: cspnext_x
      freeze_bn_stats: false
      freeze_bn_weights: false
      deepen_factor: 1.33
      widen_factor: 1.25
    kpt_encoder:
      type: ColoredKeypointEncoder
      num_joints: "num_bodyparts"
      kernel_size: [15, 15]
    img_size: [384, 384]
  backbone_output_channels: 1280
  heads:
    bodypart:
      type: RTMCCHead
      weight_init: RTMPose
      target_generator:
        type: SimCCGenerator
        input_size: [384, 384]
        smoothing_type: gaussian
        sigma: [6.93, 6.93]
        simcc_split_ratio: 2.0
        label_smooth_weight: 0.0
        normalize: false
      criterion:
        x:
          type: KLDiscreteLoss
          use_target_weight: true
          beta: 10.0
          label_softmax: true
        y:
          type: KLDiscreteLoss
          use_target_weight: true
          beta: 10.0
          label_softmax: true
      predictor:
        type: SimCCPredictor
        simcc_split_ratio: 2.0
      input_size: [384, 384]
      in_channels: 1280
      out_channels: "num_bodyparts"
      in_featuremap_size: [12, 12]  # input_size / backbone stride
      simcc_split_ratio: 2.0
      final_layer_kernel_size: 7
      gau_cfg:
        hidden_dims: 256
        s: 128
        expansion_factor: 2
        dropout_rate: 0
        drop_path: 0.0
        act_fn: "SiLU"
        use_rel_bias: false
        pos_enc: false
runner:
  optimizer:
    type: AdamW
    params:
      lr: 1e-3
  scheduler:
    type: SequentialLR
    params:
      schedulers:
      - type: LinearLR
        params:
          start_factor: 0.001
          end_factor: 1.0
          total_iters: 5
      - type: CosineAnnealingLR
        params:
          T_max: 200     # max_epochs // 2
          eta_min: 5e-5  # ~base_lr / 20
      - type: LRListScheduler
        params:
          milestones:
            - 0
          lr_list:
            - - 5e-5
      milestones:
      - 200              # max_epochs // 2
      - 400
train_settings:
  batch_size: 32
  dataloader_workers: 4
  dataloader_pin_memory: false
  epochs: 400
