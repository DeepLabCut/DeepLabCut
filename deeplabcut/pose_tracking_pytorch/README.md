Our pose-aware ReID transfomer takes features from the pre-trained multi-task CNNs and are used to train a shallow transformer with triplet loss. This model is then used to provide a stitching loss for appearance-based tracking.

Part of our transfromer code is inspired by: https://github.com/damo-cv/TransReID
