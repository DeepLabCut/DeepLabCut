# The DeepLabCut Model Zoo! 

ğŸ¦’ ğŸˆ ğŸ•â€ğŸ¦º ğŸ€ ğŸ ğŸ¦¡ ğŸ¦¦ ğŸ ğŸ« ğŸ† ğŸ¦“ ğŸ– ğŸ„ ğŸ‚ ğŸ¦–

## ğŸ  [Home page](http://modelzoo.deeplabcut.org/)

Started in 2020, the model zoo is four things: 
- (1) a collection of models that are trained on diverse data across (typically) large datsets, which means you do not need to train models yourself
- (2) a contribution website for community crowd sourcing of expertly labeled keypoints to improve models in part 1!
- (3) a no-install DeepLabCut that you can use on â™¾[Google Colab](https://colab.research.google.com/github/DeepLabCut/DeepLabCut/blob/master/examples/COLAB/COLAB_DLC_ModelZoo.ipynb), 
test our models in ğŸ•¸[the browser](https://contrib.deeplabcut.org/), or on our ğŸ¤—[HuggingFace](https://huggingface.co/spaces/DeepLabCut/MegaDetector_DeepLabCut) app!
- (4) new methods to make SuperAnimal Models that combine data across different labs/datasets, keypoints, animals/species, and use on your data!

### To see the list of available models, check out the [Home page](http://modelzoo.deeplabcut.org/). 

**Coming soon:** The DeepLabCut Project Manager GUI will allow you to use the SuperAnimal Models. You can run the model and do ``active learning" to improve performance on your data. 
Spefically, we have *new* video adaptation methods to make your tracking extra smooth and robust!

### To see our first preprint on the work, check out [our paper](https://arxiv.org/abs/2203.07436v1):

```{hint}
Here is the citation:
@article{Ye2022PanopticAP,
  title={Panoptic animal pose estimators are zero-shot performers},
  author={Shaokai Ye and Alexander Mathis and Mackenzie W. Mathis},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.07436}
}
```

