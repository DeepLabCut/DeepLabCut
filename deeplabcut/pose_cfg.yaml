dataset: willbeautomaticallyupdatedbycreate_training_datasetcode
metadataset: willbeautomaticallyupdatedbycreate_training_datasetcode
num_joints: willbeautomaticallyupdatedbycreate_training_datasetcode
all_joints: willbeautomaticallyupdatedbycreate_training_datasetcode
all_joints_names: willbeautomaticallyupdatedbycreate_training_datasetcode
init_weights: willbeautomaticallyupdatedbycreate_training_datasetcode
project_path: willbeautomaticallyupdatedbycreate_training_datasetcode


# Hyperparameters below worked well for our tasks in
# Mathis et al. Nature Neuroscience
# https://www.nature.com/articles/s41593-018-0209-y

# all locations within this distance threshold are considered
# positive training samples for detector
pos_dist_thresh: 17

# all images in the dataset will be rescaled by the following
# scaling factor to be processed by the CNN. You can select the
# optimal scale by cross-validation
global_scale: 0.8

##############################################################################
#### Augmentation variables
##############################################################################
# During training an image will be randomly scaled within the
# range [scale_jitter_lo; scale_jitter_up] to augment training data,
scale_jitter_lo: 0.5
scale_jitter_up: 1.25

# Randomly flips an image horizontally to augment training data
mirror: False

#Data loaders, i.e. with additional data augmentation options (as of 2.0.9+):
dataset_type: default
#default with be with no extra dataloaders. Other options: 'tensorpack, deterministic'
#types of datasets, see factory: deeplabcut/pose_estimation_tensorflow/dataset/factory.py
#For deterministic, see https://github.com/AlexEMG/DeepLabCut/pull/324
#For tensorpack, see https://github.com/AlexEMG/DeepLabCut/pull/409

# Auto cropping is new (was not in Nature Neuroscience 2018 paper, but introduced in Nath et al. Nat. Protocols 2019)
#and boosts performance by 2X, particularly on challenging datasets, like the cheetah in Nath et al.
# Parameters for augmentation with regard to cropping
crop: True
cropratio: 0.4 #what is the fraction of training samples with cropping?

minsize: 100 #what is the minimal frames size for cropping plus/minus ie.. [-100,100]^2 for an arb. joint
leftwidth: 400
rightwidth: 400
topheight: 400
bottomheight: 400

#limit width  [-leftwidth*u-100,100+u*rightwidth] x [-bottomwith*u-100,100+u*topwidth] where u is always a (different) random number in unit interval

# NOTE: as of DLC 2.1 these are defined when creating the training set!
# Type of the CNN to use, currently resnets + mobilenets are supported (see docs)
net_type: resnet_50
#init_weights: ./snapshot-5000


# Location refinement parameters (check https://arxiv.org/abs/1511.06645)
location_refinement: true
locref_huber_loss: true
locref_loss_weight: 0.05
locref_stdev: 7.2801

# Enabling this adds additional loss layer in the middle of the ConvNet,
# which helps accuracy (you should set to true for ResNet-101, or 152!).
intermediate_supervision: false
intermediate_supervision_layer: 12

# all images larger with size
# width * height > max_input_size*max_input_size are not used in training.
# Prevents training from crashing with out of memory exception for very
# large images.
max_input_size: 1500
# all images smaller than 64*64 will be excluded.
min_input_size: 64

# Learning rate schedule for the SGD optimizer.
multi_step:
- [0.005, 10000]
- [0.02, 430000]
- [0.002, 730000]
- [0.001, 1030000]

# How often display loss
display_iters: 1000
# How often to save training snapshot
save_iters: 50000
