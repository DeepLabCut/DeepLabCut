dataset: willbeautomaticallyupdatedbycreate_training_datasetcode
metadataset: willbeautomaticallyupdatedbycreate_training_datasetcode
num_joints: willbeautomaticallyupdatedbycreate_training_datasetcode
all_joints: willbeautomaticallyupdatedbycreate_training_datasetcode
all_joints_names: willbeautomaticallyupdatedbycreate_training_datasetcode
init_weights: willbeautomaticallyupdatedbycreate_training_datasetcode
project_path: willbeautomaticallyupdatedbycreate_training_datasetcode


# Hyperparameters below worked well for our tasks in 
# Mathis et al. Nature Neuroscience
# https://www.nature.com/articles/s41593-018-0209-y

# all locations within this distance threshold are considered
# positive training samples for detector
pos_dist_thresh: 17

# all images in the dataset will be rescaled by the following
# scaling factor to be processed by the CNN. You can select the
# optimal scale by cross-validation
global_scale: 0.8

##############################################################################
#### Augmentation variables
##############################################################################
# During training an image will be randomly scaled within the
# range [scale_jitter_lo; scale_jitter_up] to augment training data,
scale_jitter_lo: 0.5
scale_jitter_up: 1.25

# Randomly flips an image horizontally to augment training data
mirror: false

##########################################################
# Auto cropping is new (was not in Nature neuroscience manuscript)
# Parameters for augmentation with regard to cropping
crop: True
cropratio: 0.4 #what is the fraction of training samples with cropping?
minsize: 100 #what is the minimal frames size for cropping plus/minus ie.. [-100,100]^2 for an arb. joint
leftwidth: 400
rightwidth: 400
topheight: 400
bottomheight: 400

#limit width  [-leftwidth*u-100,100+u*rightwidth] x [-bottomwith*u-100,100+u*topwidth] where u is always a (different) random number in unit interval




# Type of the CNN to use, currently resnet_101 and resnet_50
# are supported
net_type: resnet_50

#init_weights: ./snapshot-5000


# Location refinement parameters (check https://arxiv.org/abs/1511.06645)
location_refinement: true
locref_huber_loss: true
locref_loss_weight: 0.05
locref_stdev: 7.2801

# Enabling this adds additional loss layer in the middle of the ConvNet,
# which helps accuracy.
intermediate_supervision: false
intermediate_supervision_layer: 12

# all images larger with size
# width * height > max_input_size*max_input_size are not used in training.
# Prevents training from crashing with out of memory exception for very
# large images.
max_input_size: 1500
# all images smaller than 64*64 will be excluded. 
min_input_size: 64

# Learning rate schedule for the SGD optimiser.
multi_step:
- [0.005, 10000]
- [0.02, 430000]
- [0.002, 730000]
- [0.001, 1030000]

# How often display loss
display_iters: 1000
# How often to save training snapshot
save_iters: 50000

