
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>DeepLabCut Model Zoo: SuperAnimal models &#8212; DeepLabCut</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples/COLAB/COLAB_YOURDATA_SuperAnimal';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="DeepLabCut for your standard (single animal) projects!" href="COLAB_YOURDATA_TrainNetwork_VideoAnalysis.html" />
    <link rel="prev" title="DeepLabCut RTMPose human pose estimation demo" href="COLAB_HumanPose_with_RTMPose.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="DeepLabCut - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="DeepLabCut - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    Welcome! 👋
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/UseOverviewGuide.html">🥳 Get started with DeepLabCut: our key recommendations</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../docs/course.html">DeepLabCut Self-paced Course</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/installation.html">How To Install DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/installTips.html">Installation Tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/docker.html">DeepLabCut Docker containers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Main User Guides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/standardDeepLabCut_UserGuide.html">DeepLabCut User Guide (for single animal projects)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/maDLC_UserGuide.html">DeepLabCut for Multi-Animal Projects</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../docs/Overviewof3D.html">3D DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/HelperFunctions.html">Helper &amp; Advanced Optional Function Documentation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Graphical User Interfaces (GUIs)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/gui/PROJECT_GUI.html">Interactive Project Manager GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/gui/napari_GUI.html">napari labeling GUI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DLC3 PyTorch Specific Docs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/pytorch/user_guide.html">DeepLabCut 3.0 - PyTorch User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/pytorch/pytorch_config.html">The PyTorch Configuration file</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/pytorch/architectures.html">DeepLabCut 3.0 - PyTorch Model Architectures</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Quick Start Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/quick-start/single_animal_quick_guide.html">QUICK GUIDE to single Animal Training:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/quick-start/tutorial_maDLC.html">Multi-animal pose estimation with DeepLabCut: A 5-minute tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🚀 Beginner's Guide to DeepLabCut</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/beginner-guides/beginners-guide.html">Using DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/beginner-guides/manage-project.html">Setting up what keypoints to track</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/beginner-guides/labeling.html">Labeling GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/beginner-guides/Training-Evaluation.html">Neural Network training and evaluation in the GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/beginner-guides/video-analysis.html">Video Analysis with DeepLabCut</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🚀 Main Demo Notebooks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="COLAB_DEMO_SuperAnimal.html">DeepLabCut SuperAnimal models</a></li>
<li class="toctree-l1"><a class="reference internal" href="COLAB_DEMO_mouse_openfield.html">DeepLabCut on Single Mouse Data Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="COLAB_3miceDemo.html">DeepLabCut MultiMouse Data Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="COLAB_HumanPose_with_RTMPose.html">DeepLabCut RTMPose human pose estimation demo</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🚀 Notebooks For Your Data</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">DeepLabCut Model Zoo: SuperAnimal models</a></li>

<li class="toctree-l1"><a class="reference internal" href="COLAB_YOURDATA_TrainNetwork_VideoAnalysis.html">DeepLabCut for your standard (single animal) projects!</a></li>
<li class="toctree-l1"><a class="reference internal" href="COLAB_YOURDATA_maDLC_TrainNetwork_VideoAnalysis.html">DeepLabCut for your multi-animal projects!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🚀 Special Feature Demos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="COLAB_transformer_reID.html">Demo: How to use our Pose Transformer for unsupervised identity tracking of animals</a></li>

<li class="toctree-l1"><a class="reference internal" href="COLAB_BUCTD_and_CTD_tracking.html">DeepLabCut - Tutorial for BUCTD models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../JUPYTER/Demo_3D_DeepLabCut.html">3D DeepLabCut Toolbox</a></li>
<li class="toctree-l1"><a class="reference internal" href="COLAB_DLC_ModelZoo.html">DeepLabCut Model Zoo user-contributed models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🧑‍🍳 Cookbook (detailed helper guides)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/convert_maDLC.html">How to convert a pre-2.2 project for use with DeepLabCut 2.2 or later</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/OtherData.html">How to use data labeled outside of DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/io.html">Input/output manipulations with DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/nn.html">Model training tips &amp; tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/post.html">Some data processing recipes!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/BatchProcessing.html">Automate training and video analysis: Batch Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/DLCMethods.html">How to write a DLC Methods Section</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/ClusteringNapari.html">Clustering in the napari-DeepLabCut GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/OpenVINO.html">Intel OpenVINO backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/flip_and_rotate.html">Improving network performance on unbalanced data via augmentation 🦇</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/pose_cfg_file_breakdown.html">The <code class="docutils literal notranslate"><span class="pre">pose_cfg.yaml</span></code> Guideline Handbook</a></li>



<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/publishing_notebooks_into_the_DLC_main_cookbook.html">Publishing Notebooks into the Main DLC Cookbook</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hardware Tips</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/TechHardware.html">Technical (Hardware) Considerations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepLabCut-Live!</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/deeplabcutlive.html">DeepLabCut-Live!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🦄 DeepLabCut Model Zoo</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/ModelZoo.html">The DeepLabCut Model Zoo!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/recipes/UsingModelZooPupil.html">Using ModelZoo models on your own datasets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepLabCut Benchmarking</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/benchmark.html">DeepLabCut benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/pytorch/Benchmarking_shuffle_guide.html">DeepLabCut Benchmarking - User Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mission &amp; Contribute</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/MISSION_AND_VALUES.html">Mission and Values of DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/roadmap.html">A development roadmap for DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/Governance.html">Governance Model of DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CONTRIBUTING.html">How to Contribute to DeepLabCut</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Citations for DeepLabCut</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docs/citation.html">How to Cite DeepLabCut</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/DeepLabCut/DeepLabCut/blob/master/examples/COLAB/COLAB_YOURDATA_TrainNetwork_VideoAnalysis.ipynb/github/DeepLabCut/DeepLabCut/blob/main/docs/examples/COLAB/COLAB_YOURDATA_SuperAnimal.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/DeepLabCut/DeepLabCut" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DeepLabCut/DeepLabCut/issues/new?title=Issue%20on%20page%20%2Fexamples/COLAB/COLAB_YOURDATA_SuperAnimal.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/examples/COLAB/COLAB_YOURDATA_SuperAnimal.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>DeepLabCut Model Zoo: SuperAnimal models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">DeepLabCut Model Zoo: SuperAnimal models</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#superanimal-in-deeplabcut-pytorch">🦄 SuperAnimal in DeepLabCut PyTorch! 🔥</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#let-s-get-going-install-the-latest-version-of-deeplabcut-into-colab"><strong>Let’s get going: install the latest version of DeepLabCut into COLAB:</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-image-video-inference">Zero-shot Image &amp; Video Inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-image-inference">Zero-shot image inference</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#upload-the-images-you-want-to-predict">Upload the images you want to predict</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#select-a-superanimal-name-and-corresponding-model-architecture">Select a SuperAnimal name and corresponding model architecture</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-video-inference">Zero-shot Video Inference</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#upload-a-video-you-want-to-predict">Upload a video you want to predict</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#choose-the-superanimal-and-the-model-name">Choose the superanimal and the model name</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-video-inference-without-video-adaptation">Zero-shot Video Inference without video adaptation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-video-inference-with-video-adaptation-unsupervised">Zero-shot Video Inference with video adaptation (unsupervised)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-with-superanimal">Training with SuperAnimal</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-deeplabcut-project">Preparing the DeepLabCut Project</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-between-different-training-baselines">Comparison between different training baselines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-the-difference-between-baselines">What is the difference between baselines?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#imagenet-transfer-learning">ImageNet transfer learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning-with-superanimal-weights">Transfer learning with SuperAnimal weights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-with-superanimal-without-keeping-full-superanimal-keypoints">Fine-tuning with SuperAnimal (without keeping full SuperAnimal keypoints)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#setup-the-weight-init-and-dataset">Setup the weight init and dataset</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-keypoint-matching">What is keypoint matching?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#display-the-confusion-matrix">Display the confusion matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#display-the-conversion-table">Display the conversion table</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-the-conversion-table-to-your-project-s-config-yaml-file">Adding the Conversion Table to your project’s <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-the-training-shuffle-and-weight-initialization-for-naive-fine-tuning-with-superanimal-weights">Prepare the training shuffle and weight initialization for (naive) fine-tuning with SuperAnimal weights</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-the-training-for-naive-fine-tuning-with-superanimal">Launch the training for (naive) fine-tuning with SuperAnimal</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-model-obtained-by-naive-fine-tuning-with-superanimal">Evaluate the model obtained by (naive) fine-tuning with SuperAnimal</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-replay-fine-tuning-with-superanimal-keeping-full-superanimal-keypoints">Memory-replay fine-tuning with SuperAnimal (keeping full SuperAnimal keypoints)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-shuffle-and-weight-initialization-for-memory-replay-finetuning-with-superanimal">Prepare training shuffle and weight initialization for memory-replay finetuning with SuperAnimal</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-the-training-for-memory-replay-fine-tuning-with-superanimal">Launch the training for memory-replay fine-tuning with SuperAnimal</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-model-obtained-by-memory-replay-finetuning-with-superanimal">Evaluate the model obtained by memory-replay finetuning with SuperAnimal</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a href="https://colab.research.google.com/github/DeepLabCut/DeepLabCut/blob/main/examples/COLAB/COLAB_YOURDATA_SuperAnimal.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="deeplabcut-model-zoo-superanimal-models">
<h1>DeepLabCut Model Zoo: SuperAnimal models<a class="headerlink" href="#deeplabcut-model-zoo-superanimal-models" title="Link to this heading">#</a></h1>
<p><img alt="alt text" src="https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1616492373700-PGOAC72IOB6AUE47VTJX/ke17ZwdGBToddI8pDm48kB8JrdUaZR-OSkKLqWQPp_YUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnBqyW03PFN2MN6T6ry5cmXqqA9xITfsbVGDrg_goIDasRCalqV8R3606BuxERAtDaQ/modelzoo.png?format=1000w" /></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="superanimal-in-deeplabcut-pytorch">
<h1>🦄 SuperAnimal in DeepLabCut PyTorch! 🔥<a class="headerlink" href="#superanimal-in-deeplabcut-pytorch" title="Link to this heading">#</a></h1>
<p>This notebook demos how to use our SuperAnimal models within DeepLabCut 3.0! Please read more in <a class="reference external" href="https://www.nature.com/articles/s41467-024-48792-2">Ye et al. Nature Communications 2024</a> about the available SuperAnimal models, and follow along below!</p>
<section id="let-s-get-going-install-the-latest-version-of-deeplabcut-into-colab">
<h2><strong>Let’s get going: install the latest version of DeepLabCut into COLAB:</strong><a class="headerlink" href="#let-s-get-going-install-the-latest-version-of-deeplabcut-into-colab" title="Link to this heading">#</a></h2>
<p><em>Also, be sure you are connected to a GPU: go to menu, click Runtime &gt; Change Runtime Type &gt; select “GPU”</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>deeplabcut
</pre></div>
</div>
</div>
</div>
<p><strong>PLEASE, click “restart runtime” from the output above before proceeding!</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">deeplabcut</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">deeplabcut.utils.auxiliaryfunctions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">auxiliaryfunctions</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deeplabcut.pose_estimation_pytorch.apis</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">superanimal_analyze_images</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deeplabcut.modelzoo</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_weight_init</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deeplabcut.modelzoo.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">create_conversion_table</span><span class="p">,</span>
    <span class="n">read_conversion_table_from_csv</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deeplabcut.modelzoo.video_inference</span><span class="w"> </span><span class="kn">import</span> <span class="n">video_inference_superanimal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deeplabcut.utils.pseudo_label</span><span class="w"> </span><span class="kn">import</span> <span class="n">keypoint_matching</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="zero-shot-image-video-inference">
<h2>Zero-shot Image &amp; Video Inference<a class="headerlink" href="#zero-shot-image-video-inference" title="Link to this heading">#</a></h2>
<p>SuperAnimal models are foundation animal pose models. They can be used for zero-shot predictions without further training on the data.
In this section, we show how to use SuperAnimal models to predict pose from images (given an image folder) and output the predicted images (with pose) into another destination folder.</p>
<section id="zero-shot-image-inference">
<h3>Zero-shot image inference<a class="headerlink" href="#zero-shot-image-inference" title="Link to this heading">#</a></h3>
<p>If you have a single Image you want to test, upload it here!</p>
<section id="upload-the-images-you-want-to-predict">
<h4>Upload the images you want to predict<a class="headerlink" href="#upload-the-images-you-want-to-predict" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">files</span>

<span class="n">uploaded</span> <span class="o">=</span> <span class="n">files</span><span class="o">.</span><span class="n">upload</span><span class="p">()</span>
<span class="k">for</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">uploaded</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;User uploaded file &#39;</span><span class="si">{</span><span class="n">filepath</span><span class="si">}</span><span class="s2">&#39; with length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">content</span><span class="p">)</span><span class="si">}</span><span class="s2"> bytes&quot;</span><span class="p">)</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
<span class="n">image_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">image_path</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># If this cell fails (e.g., when using Safari in place of Google Chrome),</span>
<span class="c1"># manually upload your video via the Files menu to the left</span>
<span class="c1"># and define `image_path` yourself with right click &gt; copy path on the image:</span>
<span class="c1">#</span>
<span class="c1"># image_path = &quot;/path/to/my/image.png&quot;</span>
<span class="c1"># image_name = os.path.splitext(image_path)[0]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="select-a-superanimal-name-and-corresponding-model-architecture">
<h4>Select a SuperAnimal name and corresponding model architecture<a class="headerlink" href="#select-a-superanimal-name-and-corresponding-model-architecture" title="Link to this heading">#</a></h4>
<p>Check Our Docs on <a class="reference external" href="https://github.com/DeepLabCut/DeepLabCut/blob/main/docs/ModelZoo.md">SuperAnimals</a> to learn more!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown ---</span>
<span class="c1"># @markdown SuperAnimal Configurations</span>
<span class="n">superanimal_name</span> <span class="o">=</span> <span class="s2">&quot;superanimal_topviewmouse&quot;</span> <span class="c1">#@param [&quot;superanimal_topviewmouse&quot;, &quot;superanimal_quadruped&quot;]</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;hrnet_w32&quot;</span> <span class="c1">#@param [&quot;hrnet_w32&quot;, &quot;resnet_50&quot;]</span>
<span class="n">detector_name</span> <span class="o">=</span> <span class="s2">&quot;fasterrcnn_resnet50_fpn_v2&quot;</span> <span class="c1">#@param [&quot;fasterrcnn_resnet50_fpn_v2&quot;, &quot;fasterrcnn_mobilenet_v3_large_fpn&quot;]</span>

<span class="c1"># @markdown ---</span>
<span class="c1"># @markdown What is the maximum number of animals you expect to have in an image</span>
<span class="n">max_individuals</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># @param {type:&quot;slider&quot;, min:1, max:30, step:1}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note you need to enter max_individuals correctly to get the correct number of predictions in the image.</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">superanimal_analyze_images</span><span class="p">(</span>
    <span class="n">superanimal_name</span><span class="p">,</span>
    <span class="n">model_name</span><span class="p">,</span>
    <span class="n">detector_name</span><span class="p">,</span>
    <span class="n">image_path</span><span class="p">,</span>
    <span class="n">max_individuals</span><span class="p">,</span>
    <span class="n">out_folder</span><span class="o">=</span><span class="s2">&quot;/content/&quot;</span><span class="p">,</span>
    <span class="n">close_figure_after_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="zero-shot-video-inference">
<h3>Zero-shot Video Inference<a class="headerlink" href="#zero-shot-video-inference" title="Link to this heading">#</a></h3>
<p>This can be done with or without video adaptation (faster, but not self-supervised fine-tuned on your data!).</p>
<section id="upload-a-video-you-want-to-predict">
<h4>Upload a video you want to predict<a class="headerlink" href="#upload-a-video-you-want-to-predict" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">files</span>

<span class="n">uploaded</span> <span class="o">=</span> <span class="n">files</span><span class="o">.</span><span class="n">upload</span><span class="p">()</span>
<span class="k">for</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">uploaded</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;User uploaded file &#39;</span><span class="si">{</span><span class="n">filepath</span><span class="si">}</span><span class="s2">&#39; with length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">content</span><span class="p">)</span><span class="si">}</span><span class="s2"> bytes&quot;</span><span class="p">)</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
<span class="n">video_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">video_path</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># If this cell fails (e.g., when using Safari in place of Google Chrome),</span>
<span class="c1"># manually upload your video via the Files menu to the left</span>
<span class="c1"># and define `video_path` yourself with right click &gt; copy path on the video.</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="choose-the-superanimal-and-the-model-name">
<h4>Choose the superanimal and the model name<a class="headerlink" href="#choose-the-superanimal-and-the-model-name" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown ---</span>
<span class="c1"># @markdown SuperAnimal Configurations</span>
<span class="n">superanimal_name</span> <span class="o">=</span> <span class="s2">&quot;superanimal_topviewmouse&quot;</span> <span class="c1">#@param [&quot;superanimal_topviewmouse&quot;, &quot;superanimal_quadruped&quot;]</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;hrnet_w32&quot;</span> <span class="c1">#@param [&quot;hrnet_w32&quot;, &quot;resnet_50&quot;]</span>
<span class="n">detector_name</span> <span class="o">=</span> <span class="s2">&quot;fasterrcnn_resnet50_fpn_v2&quot;</span> <span class="c1">#@param [&quot;fasterrcnn_resnet50_fpn_v2&quot;, &quot;fasterrcnn_mobilenet_v3_large_fpn&quot;]</span>

<span class="c1"># @markdown ---</span>
<span class="c1"># @markdown What is the maximum number of animals you expect to have in an image</span>
<span class="n">max_individuals</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># @param {type:&quot;slider&quot;, min:1, max:30, step:1}</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="zero-shot-video-inference-without-video-adaptation">
<h4>Zero-shot Video Inference without video adaptation<a class="headerlink" href="#zero-shot-video-inference-without-video-adaptation" title="Link to this heading">#</a></h4>
<p>The labeled video (and pose predictions for the video) are saved in <code class="docutils literal notranslate"><span class="pre">&quot;/content/&quot;</span></code>, with the labeled video name being <code class="docutils literal notranslate"><span class="pre">{your_video_name}_superanimal_{superanimal_name}_hrnetw32_labeled.mp4</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">video_inference_superanimal</span><span class="p">(</span>
    <span class="n">videos</span><span class="o">=</span><span class="n">video_path</span><span class="p">,</span>
    <span class="n">superanimal_name</span><span class="o">=</span><span class="n">superanimal_name</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">detector_name</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">video_adapt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">max_individuals</span><span class="o">=</span><span class="n">max_individuals</span><span class="p">,</span>
    <span class="n">dest_folder</span><span class="o">=</span><span class="s2">&quot;/content/&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="zero-shot-video-inference-with-video-adaptation-unsupervised">
<h4>Zero-shot Video Inference with video adaptation (unsupervised)<a class="headerlink" href="#zero-shot-video-inference-with-video-adaptation-unsupervised" title="Link to this heading">#</a></h4>
<p>The labeled video (and pose predictions for the video) are saved in <code class="docutils literal notranslate"><span class="pre">&quot;/content/&quot;</span></code>, with the labeled video name being <code class="docutils literal notranslate"><span class="pre">{your_video_name}_superanimal_{superanimal_name}_hrnetw32_labeled_after_adapt.mp4</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">video_inference_superanimal</span><span class="p">(</span>
    <span class="n">videos</span><span class="o">=</span><span class="p">[</span><span class="n">video_path</span><span class="p">],</span>
    <span class="n">superanimal_name</span><span class="o">=</span><span class="n">superanimal_name</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">detector_name</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">video_adapt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">max_individuals</span><span class="o">=</span><span class="n">max_individuals</span><span class="p">,</span>
    <span class="n">pseudo_threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">bbox_threshold</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">detector_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">pose_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">dest_folder</span><span class="o">=</span><span class="s2">&quot;/content/&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="training-with-superanimal">
<h2>Training with SuperAnimal<a class="headerlink" href="#training-with-superanimal" title="Link to this heading">#</a></h2>
<p>In this section, we compare different ways to train models in DeepLabCut 3.0, with or without using SuperAnimal-pretrained models.
You can compare the evaluation results and get a sense of each baseline. We have following baselines:</p>
<ul class="simple">
<li><p>ImageNet transfer learning (training without superanimal)</p></li>
<li><p>SuperAnimal transfer learning (baseline 1)</p></li>
<li><p>SuperAnimal naive fine-tuning (baseline 2)</p></li>
<li><p>SuperAnimal memory-replay fine-tuning (baseline3)</p></li>
</ul>
<p>This is done on one of your DeepLabCut projects! If you don’t have a DeepLabCut project that you can use SuperAnimal models with, you can always using the example openfield dataset <a class="reference external" href="https://github.com/DeepLabCut/DeepLabCut/tree/main/examples/openfield-Pranav-2018-10-30">available in the DeepLabCut repository</a> or the Tri-Mouse dataset available on <a class="reference external" href="https://zenodo.org/records/5851157">Zenodo</a>.</p>
<section id="preparing-the-deeplabcut-project">
<h3>Preparing the DeepLabCut Project<a class="headerlink" href="#preparing-the-deeplabcut-project" title="Link to this heading">#</a></h3>
<p>First, place your DeepLabCut project folder into you google drive! “i.e. move the folder named “Project-YourName-TheDate” into Google Drive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now, let&#39;s link to your GoogleDrive. Run this cell and follow the</span>
<span class="c1"># authorization instructions:</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You will need to edit the project path in the config.yaml file to be set to your Google Drive link!</p>
<p>Typically, this will be in the format: <code class="docutils literal notranslate"><span class="pre">/content/drive/MyDrive/yourProjectFolderName</span></code>. You can obtain this path by going to the file navigator in the left pane, finding your DeepLabCut project folder, clicking on the vertical <code class="docutils literal notranslate"><span class="pre">...</span></code> next to the folder name and selecting “Copy path”.</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">drive</span></code> folder is not immediately visible after mounting the drive, refresh the available files!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># TODO: Update the `project_path` to be the path of your DeepLabCut project!</span>
<span class="n">project_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/my-project-2024-07-17&quot;</span><span class="p">)</span>
<span class="n">config_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">project_path</span> <span class="o">/</span> <span class="s2">&quot;config.yaml&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, use the panel below to select the appropriate SuperAnimal model for your project (don’t forget to run the cell)!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown ---</span>
<span class="c1"># @markdown SuperAnimal Configurations</span>
<span class="n">superanimal_name</span> <span class="o">=</span> <span class="s2">&quot;superanimal_topviewmouse&quot;</span> <span class="c1">#@param [&quot;superanimal_topviewmouse&quot;, &quot;superanimal_quadruped&quot;]</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;hrnet_w32&quot;</span> <span class="c1">#@param [&quot;hrnet_w32&quot;, &quot;resnet_50&quot;]</span>
<span class="n">detector_name</span> <span class="o">=</span> <span class="s2">&quot;fasterrcnn_resnet50_fpn_v2&quot;</span> <span class="c1">#@param [&quot;fasterrcnn_resnet50_fpn_v2&quot;, &quot;fasterrcnn_mobilenet_v3_large_fpn&quot;]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="comparison-between-different-training-baselines">
<h3>Comparison between different training baselines<a class="headerlink" href="#comparison-between-different-training-baselines" title="Link to this heading">#</a></h3>
<p>Definition of data split: the unique combination of training images and testing images.
We create a data split named split 0. All baselines will share the data split to make fair comparisons.</p>
<ul class="simple">
<li><p>split 0 -&gt; shared by all baselines</p></li>
<li><p>shuffle 0 (split0) -&gt; imagenet transfer learning</p></li>
<li><p>shuffle 1 (split0) -&gt; superanimal transfer learning</p></li>
<li><p>shuffle 2 (split0) -&gt; superanimal naive fine-tuning</p></li>
<li><p>shuffle 3 (split0) -&gt; superanimal memory-replay fine-tuning</p></li>
</ul>
</section>
<section id="what-is-the-difference-between-baselines">
<h3>What is the difference between baselines?<a class="headerlink" href="#what-is-the-difference-between-baselines" title="Link to this heading">#</a></h3>
<p><strong>Transfer learning</strong> For canonical task-agnostic transfer learning,
the encoder learns universal visual features from a large pre-training dataset, and a randomly
initialized decoder is used to learn the pose from the downstream dataset.</p>
<p><strong>Fine-tuning</strong> For task aware
fine-tuning, both encoder and decoder learn task-related visual-pose features
in the pre-training datasets, and the decoder is fine-tuned to update pose
priors in downstream datasets. Crucially, the network has pose-estimation-specific
weights</p>
<p><strong>ImageNet transfer-learning</strong> The encoder was pre-trained from ImageNet. The decoder is trained from scratch in the downstream tasks</p>
<p><strong>SuperAnimal transfer-learning</strong> The encoder was pre-trained first from ImageNet, then in pose datasets we colleceted. Then decoder is trained from scratch in downstream tasks.</p>
<p><strong>SuperAnimal naive fine-tuning</strong> Both the encoder and the decoder were pre-trained in pose datasets we collected. In downstream datasets, we only finetune convolutional channels that correspond to the annotated keypoints in the downstream datasets. This introduces catastrophic forgetting in keypoints that are not annotated in the downstream datasets.</p>
<p><strong>SuperAnimal memory-replay fine-tuning</strong> If we apply fine-tuning with SuperAnimal without further cares, the models will forget about keypoints that are not annotated in the downstream datasets. To mitigate this, we mix the annotations and zero-shot predictions of SuperAnimal models to create a dataset that ‘replays’ the memory of the SuperAnimal keypoints.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">imagenet_transfer_learning_shuffle</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">superanimal_transfer_learning_shuffle</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">superanimal_naive_finetune_shuffle</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">superanimal_memory_replay_shuffle</span> <span class="o">=</span> <span class="mi">3</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">create_training_dataset</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">Shuffles</span><span class="o">=</span><span class="p">[</span><span class="n">imagenet_transfer_learning_shuffle</span><span class="p">],</span>
    <span class="n">net_type</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;top_down_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">detector_type</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">engine</span><span class="o">=</span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">Engine</span><span class="o">.</span><span class="n">PYTORCH</span><span class="p">,</span>
    <span class="n">userfeedback</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="imagenet-transfer-learning">
<h3>ImageNet transfer learning<a class="headerlink" href="#imagenet-transfer-learning" title="Link to this heading">#</a></h3>
<p>Historically, the transfer learning using ImageNet weights strategies assumed no “animal pose task priors” in the pretrained
model, a paradigm adopted from previous task-agnostic transfer learning.</p>
<p>You can change the number of epochs you want to train for. How long training will take depends on many parameters, including the number of images in your dataset, the resolution of the images, and the number of epochs you train for.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note we skip the detector training to save time.</span>
<span class="c1"># For Top-Down models, the evaluation is by default using ground-truth bounding</span>
<span class="c1">#  boxes. But to train a model that can be used to inference videos and images,</span>
<span class="c1">#  you have to set detector_epochs &gt; 0.</span>

<span class="n">deeplabcut</span><span class="o">.</span><span class="n">train_network</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">detector_epochs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">save_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>  <span class="c1"># if you get a CUDA OOM error when training on a GPU, reduce to 32, 16, ...!</span>
    <span class="n">displayiters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="n">imagenet_transfer_learning_shuffle</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s evaluate the performance of our trained models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">evaluate_network</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="n">Shuffles</span><span class="o">=</span><span class="p">[</span><span class="n">imagenet_transfer_learning_shuffle</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="transfer-learning-with-superanimal-weights">
<h3>Transfer learning with SuperAnimal weights<a class="headerlink" href="#transfer-learning-with-superanimal-weights" title="Link to this heading">#</a></h3>
<p>First, we prepare training shuffle for transfer-learning with SuperAnimal weights. As we’ve already create a shuffle with a train/test split that we want to reuse, we use <code class="docutils literal notranslate"><span class="pre">deeplabcut.create_training_dataset_from_existing_split</span></code> to keep the same train/test indices as in the ImageNet transfer learning shuffle.</p>
<p>We specify that we want to initialize the model weights with the selected SuperAnimal model, but without keeping the decoding layers (this is called transfer learning)!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weight_init</span> <span class="o">=</span> <span class="n">build_weight_init</span><span class="p">(</span>
    <span class="n">cfg</span><span class="o">=</span><span class="n">auxiliaryfunctions</span><span class="o">.</span><span class="n">read_config</span><span class="p">(</span><span class="n">config_path</span><span class="p">),</span> 
    <span class="n">super_animal</span><span class="o">=</span><span class="n">superanimal_name</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">detector_name</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">with_decoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">deeplabcut</span><span class="o">.</span><span class="n">create_training_dataset_from_existing_split</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">from_shuffle</span><span class="o">=</span><span class="n">imagenet_transfer_learning_shuffle</span><span class="p">,</span>
    <span class="n">shuffles</span><span class="o">=</span><span class="p">[</span><span class="n">superanimal_transfer_learning_shuffle</span><span class="p">],</span>
    <span class="n">engine</span><span class="o">=</span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">Engine</span><span class="o">.</span><span class="n">PYTORCH</span><span class="p">,</span>
    <span class="n">net_type</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;top_down_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">detector_type</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">weight_init</span><span class="o">=</span><span class="n">weight_init</span><span class="p">,</span>
    <span class="n">userfeedback</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we launch the training for transfer-learning with SuperAnimal weights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">train_network</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">detector_epochs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">save_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>  <span class="c1"># if you get a CUDA OOM error when training on a GPU, reduce to 32, 16, ...!</span>
    <span class="n">displayiters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="n">superanimal_transfer_learning_shuffle</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we evaluate the model obtained by transfer-learning with SuperAnimal weights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">evaluate_network</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="n">Shuffles</span><span class="o">=</span><span class="p">[</span><span class="n">superanimal_transfer_learning_shuffle</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fine-tuning-with-superanimal-without-keeping-full-superanimal-keypoints">
<h3>Fine-tuning with SuperAnimal (without keeping full SuperAnimal keypoints)<a class="headerlink" href="#fine-tuning-with-superanimal-without-keeping-full-superanimal-keypoints" title="Link to this heading">#</a></h3>
<section id="setup-the-weight-init-and-dataset">
<h4>Setup the weight init and dataset<a class="headerlink" href="#setup-the-weight-init-and-dataset" title="Link to this heading">#</a></h4>
<p>First we do keypoint matching. This steps make it possible to understand the correspondence between the existing annotations and SuperAnimal annotations. This step produces 3 outputs</p>
<ul class="simple">
<li><p>The confusion matrix</p></li>
<li><p>The conversion table</p></li>
<li><p>Pseudo predictions over the whole dataset</p></li>
</ul>
</section>
<section id="what-is-keypoint-matching">
<h4>What is keypoint matching?<a class="headerlink" href="#what-is-keypoint-matching" title="Link to this heading">#</a></h4>
<p>Because SuperAnimal models have their pre-defined keypoints that are potentially different from your annotations, we proposed this algorithm to minimize the gap between the model and the dataset. We use our model to perform zero-shot inference on the whole dataset. This gives pairs of predictions and ground truth for every image. Then, we cast the matching between models’ predictions (2D coordinates)
and ground truth as bipartitematching using the Euclidean distance as the cost between paired of keypoints. We then solve the matching using the Hungarian algorithm. Thus for every image, we end up getting a matching matrix where 1 counts formatch and 0 counts for non-matching. Because the models’ predictions can be noisy from image to image, we average the aforementioned matching matrix across all the images and perform another bipartite matching, resulting in the final keypoint conversion table between the model and the dataset. Note that the quality of thematching will impact the performance
of the model, especially for zero-shot. In the case where, e.g., the annotation nose is mistakenly converted to keypoint tail and vice versa, the model will have to unlearn the channel that corresponds to nose and tail (see also case study in Mathis et al.).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">keypoint_matching</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">superanimal_name</span><span class="p">,</span>
    <span class="n">model_name</span><span class="p">,</span>
    <span class="n">detector_name</span><span class="p">,</span>
    <span class="n">copy_images</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">conversion_table_path</span> <span class="o">=</span> <span class="n">project_path</span> <span class="o">/</span> <span class="s2">&quot;memory_replay&quot;</span> <span class="o">/</span> <span class="s2">&quot;conversion_table.csv&quot;</span>
<span class="n">confusion_matrix_path</span> <span class="o">=</span> <span class="n">project_path</span> <span class="o">/</span> <span class="s2">&quot;memory_replay&quot;</span> <span class="o">/</span> <span class="s2">&quot;confusion_matrix.png&quot;</span>

<span class="c1"># You can visualize the pseudo predictions, or do pose embedding clustering etc.</span>
<span class="n">pseudo_prediction_path</span> <span class="o">=</span> <span class="n">project_path</span> <span class="o">/</span> <span class="s2">&quot;memory_replay&quot;</span> <span class="o">/</span> <span class="s2">&quot;pseudo_predictions.json&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="display-the-confusion-matrix">
<h4>Display the confusion matrix<a class="headerlink" href="#display-the-confusion-matrix" title="Link to this heading">#</a></h4>
<p>The x axis lists the keypoints in the existing annotations. The y axis lists the keypoints in SuperAnimal keypoint space. Darker color encodes stronger correspondence between the human annotation and SuperAnimal annotations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matrix_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">confusion_matrix_path</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">confusion_matrix_image</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>  <span class="c1"># Hide the axes for better view</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="display-the-conversion-table">
<h4>Display the conversion table<a class="headerlink" href="#display-the-conversion-table" title="Link to this heading">#</a></h4>
<p>The gt columns represents the keypoint names in the existing dataset. The MasterName represents the corresponding keypoints in SuperAnimal keypoint space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">conversion_table_path</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">df</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="adding-the-conversion-table-to-your-project-s-config-yaml-file">
<h4>Adding the Conversion Table to your project’s <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file<a class="headerlink" href="#adding-the-conversion-table-to-your-project-s-config-yaml-file" title="Link to this heading">#</a></h4>
<p>Once you’ve run keypoint matching, you can add the conversion table to your project’s <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file, and edit it if there are some matches you think are wrong. As an example, for a top-view mouse dataset with 4 bodyparts labeled (<code class="docutils literal notranslate"><span class="pre">'snout',</span> <span class="pre">'leftear',</span> <span class="pre">'rightear',</span> <span class="pre">'tailbase'</span></code>), the conversion table mapping project bodyparts to SuperAnimal bodyparts would be added as:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># Conversion tables to fine-tune SuperAnimal weights</span>
<span class="nt">SuperAnimalConversionTables</span><span class="p">:</span>
<span class="w">  </span><span class="nt">superanimal_topviewmouse</span><span class="p">:</span>
<span class="w">    </span><span class="nt">snout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nose</span>
<span class="w">    </span><span class="nt">leftear</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">left_ear</span>
<span class="w">    </span><span class="nt">rightear</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">right_ear</span>
<span class="w">    </span><span class="nt">tailbase</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tail_base</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">create_conversion_table</span><span class="p">(</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config_path</span><span class="p">,</span>
    <span class="n">super_animal</span><span class="o">=</span><span class="n">superanimal_name</span><span class="p">,</span>
    <span class="n">project_to_super_animal</span><span class="o">=</span><span class="n">read_conversion_table_from_csv</span><span class="p">(</span>
        <span class="n">conversion_table_path</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="prepare-the-training-shuffle-and-weight-initialization-for-naive-fine-tuning-with-superanimal-weights">
<h4>Prepare the training shuffle and weight initialization for (naive) fine-tuning with SuperAnimal weights<a class="headerlink" href="#prepare-the-training-shuffle-and-weight-initialization-for-naive-fine-tuning-with-superanimal-weights" title="Link to this heading">#</a></h4>
<p>Then, when you call <code class="docutils literal notranslate"><span class="pre">build_weight_init</span></code> with <code class="docutils literal notranslate"><span class="pre">with_decoder=True</span></code>, the conversion table in your project’s <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> is used to get predictions for the correct bodyparts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weight_init</span> <span class="o">=</span> <span class="n">build_weight_init</span><span class="p">(</span>
    <span class="n">cfg</span><span class="o">=</span><span class="n">auxiliaryfunctions</span><span class="o">.</span><span class="n">read_config</span><span class="p">(</span><span class="n">config_path</span><span class="p">),</span> 
    <span class="n">super_animal</span><span class="o">=</span><span class="n">superanimal_name</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">detector_name</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">with_decoder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">deeplabcut</span><span class="o">.</span><span class="n">create_training_dataset_from_existing_split</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">from_shuffle</span><span class="o">=</span><span class="n">imagenet_transfer_learning_shuffle</span><span class="p">,</span>
    <span class="n">shuffles</span><span class="o">=</span><span class="p">[</span><span class="n">superanimal_naive_finetune_shuffle</span><span class="p">],</span>
    <span class="n">engine</span><span class="o">=</span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">Engine</span><span class="o">.</span><span class="n">PYTORCH</span><span class="p">,</span>
    <span class="n">net_type</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;top_down_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">detector_type</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">weight_init</span><span class="o">=</span><span class="n">weight_init</span><span class="p">,</span>
    <span class="n">userfeedback</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="launch-the-training-for-naive-fine-tuning-with-superanimal">
<h4>Launch the training for (naive) fine-tuning with SuperAnimal<a class="headerlink" href="#launch-the-training-for-naive-fine-tuning-with-superanimal" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">train_network</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">detector_epochs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">save_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>  <span class="c1"># if you get a CUDA OOM error when training on a GPU, reduce to 32, 16, ...!</span>
    <span class="n">displayiters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="n">superanimal_naive_finetune_shuffle</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluate-the-model-obtained-by-naive-fine-tuning-with-superanimal">
<h4>Evaluate the model obtained by (naive) fine-tuning with SuperAnimal<a class="headerlink" href="#evaluate-the-model-obtained-by-naive-fine-tuning-with-superanimal" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">evaluate_network</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">Shuffles</span><span class="o">=</span><span class="p">[</span><span class="n">superanimal_naive_finetune_shuffle</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="memory-replay-fine-tuning-with-superanimal-keeping-full-superanimal-keypoints">
<h3>Memory-replay fine-tuning with SuperAnimal (keeping full SuperAnimal keypoints)<a class="headerlink" href="#memory-replay-fine-tuning-with-superanimal-keeping-full-superanimal-keypoints" title="Link to this heading">#</a></h3>
<p><strong>Catastrophic forgetting</strong> describes a
classic problemin continual learning. Indeed, amodel gradually loses
its ability to solve previous tasks after it learns to solve new ones.
Fine-tuning a SuperAnimal models falls into the category of continual
learning: the downstream dataset defines potentially different
keypoints than those learned by the models. Thus, the models might
forget the keypoints they learned and only pick up those defined in the
target dataset. Here, retraining with the original dataset and the new
one, is not a feasible option as datasets cannot be easily shared and
more computational resources would be required.
To counter that, we treat zero-shot inference of the model as a
memory buffer that stores knowledge from the original model. When
we fine-tune a SuperAnimal model, we replace the model predicted
keypoints with the ground-truth annotations, resulting in hybrid
learning of old and new knowledge. The quality of the zero-shot predictions
can vary and we use the confidence of prediction (0.7) as a
threshold to filter out low-confidence predictions. With the threshold
set to 1, memory replay fine-tuning becomes naive-fine-tuning.</p>
<section id="prepare-training-shuffle-and-weight-initialization-for-memory-replay-finetuning-with-superanimal">
<h4>Prepare training shuffle and weight initialization for memory-replay finetuning with SuperAnimal<a class="headerlink" href="#prepare-training-shuffle-and-weight-initialization-for-memory-replay-finetuning-with-superanimal" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weight_init</span> <span class="o">=</span> <span class="n">build_weight_init</span><span class="p">(</span>
    <span class="n">cfg</span><span class="o">=</span><span class="n">auxiliaryfunctions</span><span class="o">.</span><span class="n">read_config</span><span class="p">(</span><span class="n">config_path</span><span class="p">),</span> 
    <span class="n">super_animal</span><span class="o">=</span><span class="n">superanimal_name</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">detector_name</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">with_decoder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">memory_replay</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">deeplabcut</span><span class="o">.</span><span class="n">create_training_dataset_from_existing_split</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">from_shuffle</span><span class="o">=</span><span class="n">imagenet_transfer_learning_shuffle</span><span class="p">,</span>
    <span class="n">shuffles</span><span class="o">=</span><span class="p">[</span><span class="n">superanimal_memory_replay_shuffle</span><span class="p">],</span>
    <span class="n">engine</span><span class="o">=</span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">Engine</span><span class="o">.</span><span class="n">PYTORCH</span><span class="p">,</span>
    <span class="n">net_type</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;top_down_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">detector_type</span><span class="o">=</span><span class="n">detector_name</span><span class="p">,</span>
    <span class="n">weight_init</span><span class="o">=</span><span class="n">weight_init</span><span class="p">,</span>
    <span class="n">userfeedback</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="launch-the-training-for-memory-replay-fine-tuning-with-superanimal">
<h4>Launch the training for memory-replay fine-tuning with SuperAnimal<a class="headerlink" href="#launch-the-training-for-memory-replay-fine-tuning-with-superanimal" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">train_network</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">detector_epochs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">save_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>  <span class="c1"># if you get a CUDA OOM error when training on a GPU, reduce to 32, 16, ...!</span>
    <span class="n">displayiters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="n">superanimal_memory_replay_shuffle</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluate-the-model-obtained-by-memory-replay-finetuning-with-superanimal">
<h4>Evaluate the model obtained by memory-replay finetuning with SuperAnimal<a class="headerlink" href="#evaluate-the-model-obtained-by-memory-replay-finetuning-with-superanimal" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">evaluate_network</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="n">Shuffles</span><span class="o">=</span><span class="p">[</span><span class="n">superanimal_memory_replay_shuffle</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./examples/COLAB"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="COLAB_HumanPose_with_RTMPose.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">DeepLabCut RTMPose human pose estimation demo</p>
      </div>
    </a>
    <a class="right-next"
       href="COLAB_YOURDATA_TrainNetwork_VideoAnalysis.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">DeepLabCut for your standard (single animal) projects!</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">DeepLabCut Model Zoo: SuperAnimal models</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#superanimal-in-deeplabcut-pytorch">🦄 SuperAnimal in DeepLabCut PyTorch! 🔥</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#let-s-get-going-install-the-latest-version-of-deeplabcut-into-colab"><strong>Let’s get going: install the latest version of DeepLabCut into COLAB:</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-image-video-inference">Zero-shot Image &amp; Video Inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-image-inference">Zero-shot image inference</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#upload-the-images-you-want-to-predict">Upload the images you want to predict</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#select-a-superanimal-name-and-corresponding-model-architecture">Select a SuperAnimal name and corresponding model architecture</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-video-inference">Zero-shot Video Inference</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#upload-a-video-you-want-to-predict">Upload a video you want to predict</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#choose-the-superanimal-and-the-model-name">Choose the superanimal and the model name</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-video-inference-without-video-adaptation">Zero-shot Video Inference without video adaptation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-shot-video-inference-with-video-adaptation-unsupervised">Zero-shot Video Inference with video adaptation (unsupervised)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-with-superanimal">Training with SuperAnimal</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-deeplabcut-project">Preparing the DeepLabCut Project</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-between-different-training-baselines">Comparison between different training baselines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-the-difference-between-baselines">What is the difference between baselines?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#imagenet-transfer-learning">ImageNet transfer learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning-with-superanimal-weights">Transfer learning with SuperAnimal weights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-with-superanimal-without-keeping-full-superanimal-keypoints">Fine-tuning with SuperAnimal (without keeping full SuperAnimal keypoints)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#setup-the-weight-init-and-dataset">Setup the weight init and dataset</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-keypoint-matching">What is keypoint matching?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#display-the-confusion-matrix">Display the confusion matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#display-the-conversion-table">Display the conversion table</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-the-conversion-table-to-your-project-s-config-yaml-file">Adding the Conversion Table to your project’s <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-the-training-shuffle-and-weight-initialization-for-naive-fine-tuning-with-superanimal-weights">Prepare the training shuffle and weight initialization for (naive) fine-tuning with SuperAnimal weights</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-the-training-for-naive-fine-tuning-with-superanimal">Launch the training for (naive) fine-tuning with SuperAnimal</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-model-obtained-by-naive-fine-tuning-with-superanimal">Evaluate the model obtained by (naive) fine-tuning with SuperAnimal</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-replay-fine-tuning-with-superanimal-keeping-full-superanimal-keypoints">Memory-replay fine-tuning with SuperAnimal (keeping full SuperAnimal keypoints)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-shuffle-and-weight-initialization-for-memory-replay-finetuning-with-superanimal">Prepare training shuffle and weight initialization for memory-replay finetuning with SuperAnimal</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-the-training-for-memory-replay-fine-tuning-with-superanimal">Launch the training for memory-replay fine-tuning with SuperAnimal</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-model-obtained-by-memory-replay-finetuning-with-superanimal">Evaluate the model obtained by memory-replay finetuning with SuperAnimal</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The DeepLabCut Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>Powered by <a href="https://jupyterbook.org/">Jupyter Book</a>.</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>