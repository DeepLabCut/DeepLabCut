{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DeepLabCut/DeepLabCut/blob/master/examples/COLAB/COLAB_3miceDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGChzLdc-lUJ"
   },
   "source": [
    "# DeepLabCut MultiMouse Data Demo\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1628250004229-KVYD7JJVHYEFDJ32L9VJ/DLClogo2021.jpg?format=1000w)\n",
    "\n",
    "https://github.com/DeepLabCut/DeepLabCut\n",
    "\n",
    "Note: this Colab notebook was written to accompany the Nature Methods publication [_Multi-animal pose estimation, identification and tracking with DeepLabCut_](https://www.nature.com/articles/s41592-022-01443-0) with the TensorFlow engine. To learn about DeepLabCut 3.0+ and the PyTorch engine, you can check out our other notebooks (such as [`COLAB_YOURDATA_maDLC_TrainNetwork_VideoAnalysis.ipynb`](https://github.com/DeepLabCut/DeepLabCut/blob/main/examples/COLAB/COLAB_YOURDATA_maDLC_TrainNetwork_VideoAnalysis.ipynb)).\n",
    "\n",
    "## This notebook illustrates how to use COLAB for a multi-animal DeepLabCut (maDLC) Demo 3 mouse project:\n",
    "\n",
    "- load our mini-demo data that includes a pretrained model and unlabeled video.\n",
    "- analyze a novel video.\n",
    "- assemble animals and tracklets.\n",
    "- create quality check plots and video.\n",
    "\n",
    "- To create a full maDLC pipeline please see our full docs: https://deeplabcut.github.io/DeepLabCut/README.html\n",
    "\n",
    "- Of interest is a full how-to for maDLC: https://deeplabcut.github.io/DeepLabCut/docs/maDLC_UserGuide.html\n",
    "- a quick guide to maDLC: https://deeplabcut.github.io/DeepLabCut/docs/tutorial.html\n",
    "- a demo COLAB for how to use maDLC on your own data: https://github.com/DeepLabCut/DeepLabCut/blob/main/examples/COLAB/COLAB_maDLC_TrainNetwork_VideoAnalysis.ipynb\n",
    "\n",
    "### To get started, please go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n",
    "\n",
    "As the COLAB environments were updated to CUDA 12.X and Python 3.11, we need to install DeepLabCut and TensorFlow in a distinct way to get TensorFlow to connect to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoNN2_0Z9rr_"
   },
   "outputs": [],
   "source": [
    "# Install TensorFlow, tensorpack and tf_slim versions compatible with DeepLabCut\n",
    "!pip install \"tensorflow==2.12.1\" \"tensorpack>=0.11\" \"tf_slim>=1.1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downgrade PyTorch to a version using CUDA 11.8 and cudnn 8\n",
    "# This will also install the required CUDA libraries, for both PyTorch and TensorFlow\n",
    "!pip install torch==2.3.1 torchvision --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the correct (older) version of DeepLabCut\n",
    "!pip install deeplabcut==2.3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As described in https://www.tensorflow.org/install/pip#step-by-step_instructions, \n",
    "# create symbolic links to NVIDIA shared libraries:\n",
    "!ln -svf /usr/local/lib/python3.11/dist-packages/nvidia/*/lib/*.so* /usr/local/lib/python3.11/dist-packages/tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important - Restart the Runtime for the updated packages to be imported!\n",
    "\n",
    "PLEASE, click \"restart runtime\" from the output above before proceeding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wid0GTGMAEnZ"
   },
   "source": [
    "No information needs edited in the cells below, you can simply click run on each:\n",
    "\n",
    "## Download our Demo Project from our server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PusLdqbqJi60"
   },
   "outputs": [],
   "source": [
    "# Download our demo project:\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "url_record = 'https://zenodo.org/api/records/7883589'\n",
    "response = requests.get(url_record)\n",
    "if response.status_code == 200:\n",
    "    file = response.json()['files'][0]\n",
    "    title = file['key']\n",
    "    print(f\"Downloading {title}...\")\n",
    "    with requests.get(file['links']['self'], stream=True) as r:\n",
    "        with ZipFile(BytesIO(r.content)) as zf:\n",
    "            zf.extractall(path='/content')\n",
    "else:\n",
    "    raise ValueError(f'The URL {url_record} could not be reached.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iXtySnQB0BE"
   },
   "source": [
    "## Analyze a novel 3 mouse video with our maDLC DLCRNet, pretrained on 3 mice data (i.e., here you extract detections and association costs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odYrU3o8BSAr"
   },
   "outputs": [],
   "source": [
    "import deeplabcut as dlc\n",
    "import os\n",
    "\n",
    "project_path = \"/content/demo-me-2021-07-14\"\n",
    "config_path = os.path.join(project_path, \"config.yaml\")\n",
    "video = os.path.join(project_path, \"videos\", \"videocompressed1.mp4\")\n",
    "\n",
    "dlc.analyze_videos(config_path,[video], shuffle=0, videotype=\"mp4\",auto_track=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmdSLRTOER00"
   },
   "source": [
    "## Next, you compute the local, spatio-temporal grouping and track body part assemblies frame-by-frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxYwpFB8EVGw"
   },
   "outputs": [],
   "source": [
    "TRACK_METHOD = \"ellipse\"  # Could also be \"box\", but \"ellipse\" was found to be more robust on this dataset.\n",
    "\n",
    "dlc.convert_detections2tracklets(\n",
    "    config_path,\n",
    "    [video],\n",
    "    videotype='mp4',\n",
    "    shuffle=0,\n",
    "    track_method=TRACK_METHOD,\n",
    "    ignore_bodyparts=[\"tail1\", \"tail2\", \"tailend\"],  # Some body parts can optionally be ignored during tracking for better assembly (but they are used later)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlpGe9obEvFa"
   },
   "source": [
    "## Reconstruct full animal trajectories (tracks from tracklets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKWi7JQIEvbn"
   },
   "outputs": [],
   "source": [
    "dlc.stitch_tracklets(\n",
    "    config_path,\n",
    "    [video],\n",
    "    videotype='mp4',\n",
    "    shuffle=0,\n",
    "    track_method=TRACK_METHOD,\n",
    "    n_tracks=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-d6kXqnGeUP"
   },
   "source": [
    "## Create a pretty video output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTRbuUQ1FBO0"
   },
   "outputs": [],
   "source": [
    "#Filter the predictions to remove small jitter, if desired:\n",
    "dlc.filterpredictions(config_path, \n",
    "                                 [video], \n",
    "                                 shuffle=0,\n",
    "                                 videotype='mp4', \n",
    "                                 track_method = TRACK_METHOD)\n",
    "\n",
    "dlc.create_labeled_video(\n",
    "    config_path,\n",
    "    [video],\n",
    "    videotype='mp4',\n",
    "    shuffle=0,\n",
    "    color_by=\"individual\",\n",
    "    keypoints_only=False,\n",
    "    draw_skeleton=True,\n",
    "    filtered=True,\n",
    "    track_method=TRACK_METHOD,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYNlrgeNUG4U"
   },
   "source": [
    "Now, on the left panel if you click the folder icon, you will see the project folder \"demo-me..\"; click on this and go into \"videos\" and you can find the \"..._id_labeled.mp4\" video, which you can double-click on to download and inspect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7GWMBJUA9x5"
   },
   "source": [
    "## Create Plots of your data:\n",
    "\n",
    "> after running, you can look in \"videos\", \"plot-poses\" to check out the trajectories! (sometimes you need to click the folder refresh icon to see it). Within the folder, for example, see plotmus1.png to vide the bodyparts over time vs. pixel position.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7w9BDIA7BB_i"
   },
   "outputs": [],
   "source": [
    "dlc.plot_trajectories(config_path, [video], shuffle=0,videotype='mp4', track_method=TRACK_METHOD)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of 3micedemo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
