{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6eec817-48c7-40d7-92ab-f20705562a62",
   "metadata": {},
   "source": [
    "# Let's try to figure out how to develop RTMDet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8618fe-8064-4c3c-9840-ff0c19525aa7",
   "metadata": {},
   "source": [
    "## First, let's understand what is the difference between CSPNext and RTMPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8920742e-91fd-4887-b7b4-fc39f69ac626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc13...\n",
      "<class 'deeplabcut.pose_estimation_pytorch.models.backbones.cspnext.CSPNeXt'>\n",
      "Nb parameters: 12279432\n",
      "Shape of output of dummy tensor: torch.Size([1, 768, 8, 8])\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'deeplabcut.pose_estimation_pytorch.models.model.PoseModel'>\n",
      "Nb parameters: 13172879\n",
      "Shape of output of dummy tensor: torch.Size([1, 5, 512]) , torch.Size([1, 5, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "# ----\n",
    "\n",
    "# First, let's create a CSPNeXt object\n",
    "from deeplabcut.pose_estimation_pytorch.models.backbones.cspnext import CSPNeXt\n",
    "\n",
    "MODEL_VARIANTS = {\n",
    "    \"cspnext_s\":  {\"model_name\": \"cspnext_s\", \"freeze_bn_stats\": False, \"freeze_bn_weights\": False, \"deepen_factor\": 0.33, \"widen_factor\": 0.5},\n",
    "    \"cspnext_m\": {\"model_name\": \"cspnext_m\", \"freeze_bn_stats\": False, \"freeze_bn_weights\": False, \"deepen_factor\": 0.67, \"widen_factor\": 0.75},\n",
    "    \"cspnext_x\":  {\"model_name\": \"cspnext_x\", \"freeze_bn_stats\": False, \"freeze_bn_weights\": False, \"deepen_factor\": 1.33, \"widen_factor\": 1.25},\n",
    "}\n",
    "\n",
    "my_variant = \"cspnext_m\" # choose from cspnext_s , cspnext_m , cspnext_x\n",
    "\n",
    "cspnext = CSPNeXt(**MODEL_VARIANTS[my_variant])\n",
    "\n",
    "print(type(cspnext)) # cspnext is of type deeplabcut.pose_estimation_pytorch.models.backbones.cspnext.CSPNeXt , which is a nn.Module\n",
    "print(f\"Nb parameters: {sum(p.numel() for p in cspnext.parameters())}\")\n",
    "# print(cspnext) # This floods the output\n",
    "y = cspnext(x)\n",
    "print(f\"Shape of output of dummy tensor: {y.shape}\")\n",
    "\n",
    "torch.save(cspnext.state_dict(), f\"/home/max/tmp/rtmdet_dev/dlc_{my_variant}.pth\")\n",
    "\n",
    "mmdetection_state_dict = torch.load(\"/home/max/tmp/rtmdet_dev/remaped_mmdetection_rtmdet_m_backbone.pth\", map_location=\"cpu\")\n",
    "\n",
    "cspnext.load_state_dict(mmdetection_state_dict)\n",
    "\n",
    "print(\"-\"* 80)\n",
    "\n",
    "# Next, let's create a RTMPose nn.Module object\n",
    "from deeplabcut.pose_estimation_pytorch.config.utils import get_config_folder_path, replace_default_values\n",
    "from deeplabcut.core.config import read_config_as_dict\n",
    "from deeplabcut.pose_estimation_pytorch.models import PoseModel\n",
    "\n",
    "net_type = \"rtmpose_m\" # for example\n",
    "nb_bodyparts = 5 # for example\n",
    "\n",
    "configs_dir = get_config_folder_path()\n",
    "architecture = net_type.split(\"_\")[0]\n",
    "cfg_path = cfg_path = configs_dir / architecture / f\"{net_type}.yaml\"\n",
    "model_cfg = read_config_as_dict(cfg_path)\n",
    "model_cfg = replace_default_values(\n",
    "    model_cfg,\n",
    "    num_bodyparts=nb_bodyparts,\n",
    ") # Interesting observation: the yaml file defines values that depend on nb_individuals and/or nb_bodyparts, and are updated with real values once known (when creating the actual pytorch_config.yaml)\n",
    "rtmpose = PoseModel.build(model_cfg[\"model\"]) # here, there might be some optional parameters, todo investigate\n",
    "print(type(rtmpose))\n",
    "print(f\"Nb parameters: {sum(p.numel() for p in rtmpose.parameters())}\")\n",
    "# print(rtmpose) # This floods the output\n",
    "z = rtmpose(x)\n",
    "print(f\"Shape of output of dummy tensor: {z['bodypart']['x'].shape} , {z['bodypart']['y'].shape}\")\n",
    "# Okay so basically, the first level keys are defined by the pytorch_config.yaml (in the heads block), and the second level keys are defined in the RTMCCHead forward method.\n",
    "# The first level keys are certainly added when doing PoseModel.build\n",
    "# When printing rtmpose, there are different submodules (backbone, head). They are very certainly created during PoseModel.build()\n",
    "# The differences in sizes of rtmpose are the same ones as the difference in sizes of cspnext. \n",
    "# The different parameters (deepen_factor, widen_factor, backbone_output_channels) are configured in the rtmpose yaml files.\n",
    "\n",
    "# - state_dict() returns a dictionary containing all the modelâ€™s learnable parameters and buffers,\n",
    "# while load_state_dict() restores those values into a model with the same architecture.\n",
    "\n",
    "rtmpose.backbone.load_state_dict(mmdetection_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3521a-ab8c-44dc-81dd-975cb8c9d864",
   "metadata": {},
   "source": [
    "## Then, let's dive into how the existing detectors work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f5165-9431-4bb8-abcc-298b9524fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplabcut.pose_estimation_pytorch.models.detectors.fasterRCNN import FasterRCNN\n",
    "\n",
    "# Instantiate a pretrained Faster R-CNN with a MobileNetV3 backbone\n",
    "detector = FasterRCNN(\n",
    "    variant=\"fasterrcnn_mobilenet_v3_large_fpn\",  # or \"fasterrcnn_resnet50_fpn\"\n",
    "    pretrained=True,                              # load COCO pretrained weights\n",
    "    box_score_thresh=0.05,                        # filter weak detections\n",
    ")\n",
    "# This throws away the Head and loads an other one, so the Head is not pretrained anymore.\n",
    "\n",
    "# Dummy input batch of 2 RGB images, 3x224x224 each\n",
    "images = [torch.rand(3, 224, 224), torch.rand(3, 224, 224)]\n",
    "\n",
    "# During inference (no targets)\n",
    "detector.eval()\n",
    "with torch.no_grad():\n",
    "    losses, detections = detector(images)\n",
    "\n",
    "print(detections)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc8ef3-a43a-478b-a87b-ecec9655a1b9",
   "metadata": {},
   "source": [
    "## Finally, let's instantiate the official RTMDet network for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c510989-d6bf-47d7-b2f1-5e8d54623fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/Software/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mmdet.models.detectors.rtmdet.RTMDet'>\n",
      "Nb parameters: 94855572\n",
      "<class 'mmdet.models.backbones.cspnext.CSPNeXt'>\n",
      "<class 'mmdet.models.necks.cspnext_pafpn.CSPNeXtPAFPN'>\n",
      "<class 'mmdet.models.dense_heads.rtmdet_head.RTMDetSepBNHead'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52322/1718226531.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dlc_state_dict = torch.load(\"/home/max/tmp/rtmdet_dev/remaped_dlc_cspnext_x.pth\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this must be performed in the openmmlab environment.\n",
    "from mmdet.utils import register_all_modules\n",
    "register_all_modules()\n",
    "\n",
    "import torch\n",
    "from mmengine import Config\n",
    "from mmdet.registry import MODELS\n",
    "\n",
    "#x = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "my_variant = \"rtmdet_x\" # choose from rtmdet_tiny , rtmdet_s , rtmdet_m , rtmdet_l , rtmdet_x\n",
    "rtmdet_cfg = Config.fromfile(f\"/home/max/Work/mmdetection/configs/rtmdet/{my_variant}_8xb32-300e_coco.py\")\n",
    "\n",
    "# Build the model\n",
    "rtmdet = MODELS.build(rtmdet_cfg.model)\n",
    "\n",
    "# Put it in evaluation mode (no gradients, etc.)\n",
    "rtmdet.eval()\n",
    "\n",
    "print(type(rtmdet))\n",
    "\n",
    "print(f\"Nb parameters: {sum(p.numel() for p in rtmdet.parameters())}\")\n",
    "\n",
    "#print(rtmdet) # This floods the output\n",
    "print(type(rtmdet.backbone))\n",
    "print(type(rtmdet.neck))\n",
    "print(type(rtmdet.bbox_head))\n",
    "\n",
    "torch.save(rtmdet.backbone.state_dict(), f\"/home/max/tmp/rtmdet_dev/mmdetection_{my_variant}_backbone.pth\")\n",
    "\n",
    "dlc_state_dict = torch.load(\"/home/max/tmp/rtmdet_dev/remaped_dlc_cspnext_x.pth\", map_location=\"cpu\")\n",
    "\n",
    "rtmdet.backbone.load_state_dict(dlc_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2524f01-e76b-4dcc-a76e-4eaed18ac1e4",
   "metadata": {},
   "source": [
    "## This is a DetInferencer from MMDetection (used by the demo script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646a08e-4aa2-47ea-8088-e59bb5bfb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "inferencer = DetInferencer(\n",
    "    model=\"/home/max/Work/mmdetection/rtmdet_tiny_8xb32-300e_coco.py\",\n",
    "    weights=\"/home/max/Work/mmdetection/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "inferencer.model.test_cfg.chunked_size = -1\n",
    "\n",
    "inferencer(\n",
    "    inputs=\"/home/max/Work/mmdetection/demo/demo.jpg\",\n",
    "    out_dir=\"/home/max/Work/mmdetection/outputs\",\n",
    "    no_save_pred=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008bbb4-492f-4407-a305-76f1a2ad71e0",
   "metadata": {},
   "source": [
    "## Let's try to load one saved state dict of CSPNeXt into the other, and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c75b50a-029c-4dbd-bc95-d87935166878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def remap_cspnext_keys(state_dict, direction):\n",
    "    \"\"\"\n",
    "    direction:\n",
    "      - 'dlc_to_mmdet': makes DLC keys compatible with MMDet\n",
    "      - 'mmdet_to_dlc': makes MMDet keys compatible with DLC\n",
    "    \"\"\"\n",
    "    new_sd = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_k = k\n",
    "        if direction == \"dlc_to_mmdet\":\n",
    "            # make DLC checkpoint loadable into MMDet model\n",
    "            new_k = new_k.replace(\".norm\", \".bn\")\n",
    "        elif direction == \"mmdet_to_dlc\":\n",
    "            # make MMDet checkpoint loadable into DLC model\n",
    "            new_k = new_k.replace(\".bn\", \".norm\")\n",
    "        new_sd[new_k] = v\n",
    "    return new_sd\n",
    "\n",
    "\n",
    "dlc_cspnext_variants = (\"cspnext_s\", \"cspnext_m\", \"cspnext_x\")\n",
    "mmdetection_cspnext_variants = (\"rtmdet_s\", \"rtmdet_m\", \"rtmdet_x\")\n",
    "\n",
    "for dlc_cspnext_variant, mmdetection_cspnext_variant in zip(dlc_cspnext_variants, mmdetection_cspnext_variants):\n",
    "    snapshots_dir = Path(\"/home/max/tmp/rtmdet_dev/\")\n",
    "    dlc_snapshot_path = snapshots_dir / f\"dlc_{dlc_cspnext_variant}.pth\"\n",
    "    mmdetection_snapshot_path = snapshots_dir / f\"mmdetection_{mmdetection_cspnext_variant}_backbone.pth\"\n",
    "\n",
    "    dlc_state_dict = torch.load(dlc_snapshot_path, map_location=\"cpu\")\n",
    "    mmdetection_state_dict = torch.load(mmdetection_snapshot_path, map_location=\"cpu\")\n",
    "\n",
    "    dlc_state_dict_remaped = remap_cspnext_keys(dlc_state_dict, direction=\"dlc_to_mmdet\")\n",
    "    mmdetection_state_dict_remaped = remap_cspnext_keys(mmdetection_state_dict, direction=\"mmdet_to_dlc\")\n",
    "\n",
    "    torch.save(dlc_state_dict_remaped, snapshots_dir / f\"remaped_dlc_{dlc_cspnext_variant}.pth\")\n",
    "    torch.save(mmdetection_state_dict_remaped, snapshots_dir / f\"remaped_mmdetection_{mmdetection_cspnext_variant}_backbone.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c2a97-0533-4824-871f-adaf5afa045f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
